{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning of a GStore Customer Dataset</h1>\n",
    "<p>The goal of this data cleaning is to prepare the dataset before using it for data analysis and prediction. The dataset is downloaded from Kaggle Competition (https://www.kaggle.com/c/ga-customer-revenue-prediction), and it contains Google Merchandise Store's customer transactions from August 1st, 2016 to October 15th, 2018.\n",
    "</p>This notebook contains the steps I have done to clean the dataset.\n",
    "<p>\n",
    "<ol>\n",
    "    <li>Loading the Datasets and Flatten JSON Columns</li>\n",
    "    <li>Examining the columns</li>\n",
    "    <li>Investigating the values</li>\n",
    "    <ol>\n",
    "        <li>Finding columns having null values</li>\n",
    "        <li>Replacing null values with 0</li>\n",
    "        <li>Replace '(not set)', '(none)', '(not provided)' with '(missing)'</li>\n",
    "        <li>Dropping columns having uniform value</li>\n",
    "    </ol>\n",
    "    <li>Fixing columns data type</li>\n",
    "</ol>\n",
    "<p>Reference of Google Analytics Schema: https://support.google.com/analytics/answer/3437719?hl=en</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_int64_dtype\n",
    "from pandas.api.types import is_float_dtype\n",
    "from pandas.api.types import is_object_dtype\n",
    "from pandas.api.types import is_bool_dtype\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Loading the Datasets and Flatten JSON Columns</h2>\n",
    "<p>Google Analytics Customer Transaction has five RECORD data type: 'totals', 'trafficSource', 'device', 'customDimensions', 'geoNetwork', 'hits'. Because 'geoNetwork.subContinent' and 'total.hits' can be used as substitute for 'customDimensions' and 'hits', these two RECORDs will not be flattended in the following step.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset file's path\n",
    "df_read_path = \"../data/train_v2_small.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function load_df(csv_path, nrows)\n",
    "    This function reads a dataset, flattens the JSON columns in json_cols list, and \n",
    "    contructs a dataframe that contains columns written in the use_cols list. The use_cols is needed \n",
    "    to prevent column duplicates after JSON flattening.\n",
    "Input:\n",
    "    1. csv_path: the dataset's file name to load.\n",
    "    2. nrows: number of rows to read during the data loading.\n",
    "Output:\n",
    "    A dataframe of the dataset.\n",
    "\n",
    "\"\"\"\n",
    "def load_df(csv_path=df_read_path, nrows=None):\n",
    "    JSON_COLUMNS = ['totals', 'trafficSource', 'device', 'geoNetwork']\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     converters = {column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype= {'fullVisitorId': 'str', 'date': 'str'}, # Important!!\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train_v2_small.csv. Shape: (2000, 59)\n"
     ]
    }
   ],
   "source": [
    "#read train_v2_small.csv and flatten json columns\n",
    "df = load_df(csv_path=df_read_path, nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'hits' and 'customDimension' columns which are not flattened\n",
    "df.drop(['hits', 'customDimensions'], axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Examining the columns</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function find_columns_datatype(dataframe, datatype='object')\n",
    "    This function finds the data type of all columns in the dataframe.\n",
    "Input:\n",
    "    dataframe: dataframe's name.\n",
    "    datatype: datatype's name, with 'object' as the default.\n",
    "Output:\n",
    "    a list of column name(s) having datatype requested.\n",
    "\"\"\"\n",
    "def find_columns_datatype (dataframe, datatype='object'):\n",
    "    cols = []\n",
    "    if (datatype == 'int'):\n",
    "        for col in dataframe.columns:\n",
    "            if (is_int64_dtype (dataframe[col])):\n",
    "                cols.append(col)\n",
    "    elif (datatype == 'float'):\n",
    "        for col in dataframe.columns:\n",
    "            if (is_float_dtype (dataframe[col])):\n",
    "                cols.append(col)\n",
    "    elif (datatype == 'bool'):\n",
    "        for col in dataframe.columns:\n",
    "            if (is_bool_dtype (dataframe[col])):\n",
    "                cols.append(col)\n",
    "    elif (datatype == 'string'):\n",
    "        for col in dataframe.columns:\n",
    "            if (is_string_dtype (dataframe[col])):\n",
    "                cols.append(col)                \n",
    "    elif (datatype == 'object'):\n",
    "        for col in dataframe.columns:\n",
    "            if (is_object_dtype (dataframe[col])):\n",
    "                cols.append(col)\n",
    "    print(f'{len(cols)} columns have {datatype} : {cols}')\n",
    "    return (cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 columns have bool : ['device.isMobile']\n"
     ]
    }
   ],
   "source": [
    "bool_cols = find_columns_datatype(df, 'bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns have int : ['visitId', 'visitNumber', 'visitStartTime']\n"
     ]
    }
   ],
   "source": [
    "int_cols = find_columns_datatype(df, 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columns have float : []\n"
     ]
    }
   ],
   "source": [
    "float_cols = find_columns_datatype(df, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 columns have object : ['channelGrouping', 'date', 'fullVisitorId', 'socialEngagementType', 'totals.visits', 'totals.hits', 'totals.pageviews', 'totals.bounces', 'totals.newVisits', 'totals.sessionQualityDim', 'totals.timeOnSite', 'totals.transactions', 'totals.transactionRevenue', 'totals.totalTransactionRevenue', 'trafficSource.campaign', 'trafficSource.source', 'trafficSource.medium', 'trafficSource.keyword', 'trafficSource.adwordsClickInfo.criteriaParameters', 'trafficSource.referralPath', 'trafficSource.isTrueDirect', 'trafficSource.adContent', 'trafficSource.adwordsClickInfo.page', 'trafficSource.adwordsClickInfo.slot', 'trafficSource.adwordsClickInfo.gclId', 'trafficSource.adwordsClickInfo.adNetworkType', 'trafficSource.adwordsClickInfo.isVideoAd', 'device.browser', 'device.browserVersion', 'device.browserSize', 'device.operatingSystem', 'device.operatingSystemVersion', 'device.mobileDeviceBranding', 'device.mobileDeviceModel', 'device.mobileInputSelector', 'device.mobileDeviceInfo', 'device.mobileDeviceMarketingName', 'device.flashVersion', 'device.language', 'device.screenColors', 'device.screenResolution', 'device.deviceCategory', 'geoNetwork.continent', 'geoNetwork.subContinent', 'geoNetwork.country', 'geoNetwork.region', 'geoNetwork.metro', 'geoNetwork.city', 'geoNetwork.cityId', 'geoNetwork.networkDomain', 'geoNetwork.latitude', 'geoNetwork.longitude', 'geoNetwork.networkLocation']\n"
     ]
    }
   ],
   "source": [
    "obj_cols = find_columns_datatype(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Investigating the values</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. Finding columns having null values</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function find_cols_missing_values(dataframe)\n",
    "    This function finds columns that have at least one null value in it.\n",
    "Input: \n",
    "    dataframe: the name of the dataframe\n",
    "Output:\n",
    "    list of columns having at least one null value, its total missing values, \n",
    "    and percentage of missing value.\n",
    "\"\"\"\n",
    "def find_cols_missing_values(dataframe):\n",
    "    total_sum = dataframe.isnull().sum()\n",
    "    total_count = dataframe.isnull().count()\n",
    "    \n",
    "    total = total_sum.sort_values(ascending=False)\n",
    "    percent = (total_sum / total_count * 100).sort_values(ascending=False)\n",
    "\n",
    "    total_percent = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print(\"Columns having at least one null values: \")\n",
    "    print(total_percent[~(total_percent['Total'] == 0)]) #print only columns having at least 1 null values\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns having at least one null values: \n",
      "                                              Total  Percent\n",
      "totals.totalTransactionRevenue                 1976    98.80\n",
      "totals.transactionRevenue                      1976    98.80\n",
      "totals.transactions                            1976    98.80\n",
      "trafficSource.adContent                        1776    88.80\n",
      "trafficSource.adwordsClickInfo.adNetworkType   1753    87.65\n",
      "trafficSource.adwordsClickInfo.gclId           1753    87.65\n",
      "trafficSource.adwordsClickInfo.isVideoAd       1753    87.65\n",
      "trafficSource.adwordsClickInfo.page            1753    87.65\n",
      "trafficSource.adwordsClickInfo.slot            1753    87.65\n",
      "trafficSource.referralPath                     1444    72.20\n",
      "trafficSource.isTrueDirect                     1428    71.40\n",
      "totals.bounces                                 1023    51.15\n",
      "totals.timeOnSite                               978    48.90\n",
      "trafficSource.keyword                           839    41.95\n",
      "totals.newVisits                                488    24.40\n"
     ]
    }
   ],
   "source": [
    "#Find columns having null values\n",
    "find_cols_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Based on the information of columns' value frequencies, there are three columns, 'device.isMobile', 'trafficSource.isTrueDirect', 'trafficSource.adwordsClickInfo.isVideoAd', that have boolean data type. Two of them have significant amount of missing values. According to the information in <a href=\"https://support.google.com/analytics/answer/3437719?hl=en\">Google Analytics Schema</a>, these missing values can be replaced with False.\n",
    "</p>\n",
    "<ol>\n",
    "    <li>'trafficSource.isTrueDirect': missing data can be filled with False, indicates that the source is direct URL.</li>\n",
    "    <li>'trafficSource.adwordsClickInfo.isVideoAd': missing data can be filled with True, indicates that the video ad is not YouTube Trueview.</li>\n",
    "    <li>'totals.pageviews': missing data can be filled with 1, indicates that there is no pageview in the session.</li>\n",
    "    <li>'totals.bounces': missing data can be filled with 0, indicates that the session is not bounced.</li>                       <li>'totals.newVisits': missing data can be filled with 0, indicates that it is a return customer</li>\n",
    "    <li>'totals.sessionQualityDim': missing data should be filled with 0, indicates that the Session Quality is not calculated for the selected time range.</li>\n",
    "    <li>'totals.timeOnSite': missing data can be filled with 0, indicates that there is 0 second on site in the session.</li>\n",
    "    <li>'totals.transactions': missing data should be filled with 0, indicates that there is no transaction during the session.</li>\n",
    "    <li>'totals.transactionRevenue': missing data should be filled with 0, indicates that there is no transaction during the session.</li>\n",
    "    <li>'totals.totalTransactionRevenue': missing data should be filled with 0, indicates that there is no transaction during the session.</li>\n",
    "    <li>'trafficSource.adwordsClickInfo.page': missing data can be filled with 0, indicates there is no ad in the search result.</li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Replacing null values with 0</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values with False\n",
    "df['trafficSource.isTrueDirect'].fillna(False, inplace=True)\n",
    "\n",
    "#Fill null values with True\n",
    "df['trafficSource.adwordsClickInfo.isVideoAd'].fillna(True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function fill_null_zero(dataframe, list_cols) \n",
    "    This function replace null values in columns with 0.\n",
    "Input: \n",
    "    dataframe: name of dataframe\n",
    "    list_cols: list of columns to replace\n",
    "Output: dataframe without NULL values\n",
    "\"\"\"\n",
    "def fill_null_zero(dataframe, list_cols):\n",
    "    for col in list_cols:\n",
    "        dataframe[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill null values with 0\n",
    "num_cols = ['totals.transactionRevenue','totals.totalTransactionRevenue','totals.transactions','trafficSource.adwordsClickInfo.page','totals.timeOnSite','totals.sessionQualityDim','totals.pageviews','totals.bounces', 'totals.newVisits']\n",
    "fill_null_zero(df, num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C. Replace '(not set)', '(none)', '(not provided)' with '(missing)'</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function replace_values_nan(dataframe, list_cols, word)\n",
    "    This function is to replace the word found in list_cols with '(missing)'\n",
    "Input:\n",
    "    dataframe: the name of the dataframe\n",
    "    list_cols: list of columns to look at\n",
    "    word: the string to replace with '(missing)'\n",
    "\"\"\"\n",
    "def replace_values_missing(dataframe, list_cols, word):\n",
    "    for col in list_cols:\n",
    "        dataframe.loc[dataframe[col] == word, col] = np.nan\n",
    "    for col in list_cols:    \n",
    "        dataframe[col].fillna('(missing)', inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace null values with 'NaN' in object type except several columns\n",
    "replace_values_missing(df, obj_cols, '(not set)')\n",
    "replace_values_missing(df, obj_cols, '(none)')\n",
    "replace_values_missing(df, obj_cols, '(not provided)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns having at least one null values: \n",
      "Empty DataFrame\n",
      "Columns: [Total, Percent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Check again if there is any null value in df\n",
    "find_cols_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>D. Dropping columns having uniform value</h3>\n",
    "<p>Column that has the same value throughout its cells will not contribute to the variation in the dependent variables (transaction and revenue), that it can be eliminated from the dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function find_uniform_column(dataframe, list_cols)\n",
    "    This function finds columns having the same value throughout the column.\n",
    "Input:\n",
    "    dataframe: the name of the dataframe\n",
    "    list_cols: the list of columns to inspect\n",
    "Output:\n",
    "    list of columns having uniform value in it.\n",
    "\"\"\"\n",
    "def find_uniform_column(dataframe, list_cols):\n",
    "    uniform_cols = []\n",
    "    for col in list_cols:\n",
    "        if (df[col].nunique(dropna = False) == 1):\n",
    "            uniform_cols.append(col)\n",
    "    return uniform_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['date', 'socialEngagementType', 'totals.visits', 'trafficSource.adwordsClickInfo.criteriaParameters', 'device.browserVersion', 'device.browserSize', 'device.operatingSystemVersion', 'device.mobileDeviceBranding', 'device.mobileDeviceModel', 'device.mobileInputSelector', 'device.mobileDeviceInfo', 'device.mobileDeviceMarketingName', 'device.flashVersion', 'device.language', 'device.screenColors', 'device.screenResolution', 'geoNetwork.cityId', 'geoNetwork.latitude', 'geoNetwork.longitude', 'geoNetwork.networkLocation']\n"
     ]
    }
   ],
   "source": [
    "#Find the columns having the same value throughout the column\n",
    "uni_bool_cols = find_uniform_column(df, bool_cols)\n",
    "print(uni_bool_cols)\n",
    "uni_int_cols = find_uniform_column(df, int_cols)\n",
    "print(uni_int_cols)\n",
    "uni_obj_cols = find_uniform_column(df, obj_cols)\n",
    "print(uni_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with uniform value\n",
    "df.drop(uni_obj_cols, axis='columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 37)\n"
     ]
    }
   ],
   "source": [
    "#The size of df \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Fixing columns data type</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Some columns have limited different values can have categorical data type.</p>\n",
    "<ol>\n",
    "<li>channelGrouping : 8</li>\n",
    "<li>trafficSource.campaign : 33</li>\n",
    "<li>trafficSource.medium : 7</li>\n",
    "<li>trafficSource.adwordsClickInfo.slot : 4 (including 1633063 'missing')</li>\n",
    "<li>trafficSource.source : 345</li>\n",
    "<li>device.operatingSystem : 24 </li>\n",
    "<li>device.deviceCategory : 3</li>\n",
    "<li>geoNetwork.continent : 6</li>\n",
    "<li>geoNetwork.subContinent : 23</li>\n",
    "<li>geoNetwork.country : 228</li>\n",
    "<li>geoNetwork.region : 483</li>\n",
    "<li>geoNetwork.metro : 123</li>\n",
    "<li>geoNetwork.city : 956</li>\n",
    "<li>device.browser : 129</li>\n",
    "<li>trafficSource.adContent : 77 (including 1643600 'missing')</li>\n",
    "<li>trafficSource.adwordsClickInfo.adNetworkType : 4 (including 1633063 'missing')</li>\n",
    "</ol>\n",
    "The rest of the columns stay with string type:\n",
    "<ol>\n",
    "<li>date</li>\n",
    "<li>fullVisitorId</li>\n",
    "<li>trafficSource.adwordsClickInfo.gclId</li> \n",
    "<li>trafficSource.keyword : 4547 (including 1052780 'missing')</li>\n",
    "<li>trafficSource.referralPath : 3197 (including 1142073 'missing')</li>\n",
    "<li>geoNetwork.networkDomain : 41982</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check again the data type of all columns \n",
    "int_cols = find_columns_datatype(df, 'int')\n",
    "bool_cols = find_columns_datatype(df, 'bool')\n",
    "obj_cols = find_columns_datatype(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the data type of boolean and 16 object type columns to category type\n",
    "str_cat_cols= ['device.isMobile', 'trafficSource.isTrueDirect', 'trafficSource.adwordsClickInfo.isVideoAd', 'channelGrouping', 'trafficSource.campaign', 'trafficSource.medium', 'trafficSource.adwordsClickInfo.slot', 'trafficSource.source', 'device.operatingSystem', 'device.deviceCategory', 'geoNetwork.continent', 'geoNetwork.subContinent', 'geoNetwork.country', 'geoNetwork.region', 'geoNetwork.metro', 'geoNetwork.city', 'device.browser', 'trafficSource.adContent', 'trafficSource.adwordsClickInfo.adNetworkType']\n",
    "for col in str_cat_cols:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the data type of 10 object type columns to integer type\n",
    "str_int_cols = ['totals.hits', 'totals.pageviews', 'totals.bounces', 'totals.newVisits', 'totals.sessionQualityDim', 'totals.timeOnSite', 'totals.transactions', 'totals.transactionRevenue', 'totals.totalTransactionRevenue', 'trafficSource.adwordsClickInfo.page']\n",
    "for col in str_int_cols:\n",
    "    df[col] = df[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a file for next use\n",
    "df_write_path = \"../data/train_small_clean.csv\"\n",
    "\n",
    "df.to_csv(df_write_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "name": "Cleaning_Data",
  "notebookId": 3372830168734072
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
